# 1. With the likelihood function and the prior over the model parameter w defined as below, please derive the posterior probability distribution of w and the predictive distribution of t for a new sample x.

- Likelihood function $p(t|w)$: exponential of a quadratic function of $w$

$$ p(t|\bold{X},w,\beta) = \prod_{n=1}^{N}\mathcal{N}(t_{n}|w^{T}\phi(\bold{x}_{n}),\beta^{-1})$$

- (Conjugate prior) Gaussian distribution 

$$p(w) = \mathcal{N}(w|m_{0},S_{0})$$





## Ans 1

이 문제는 교과서 173 페이지의 "Bayesian linear regression" 에 관한 문제입니다. 

사후분포는 사전 분포와 가능도 함수의 곱에 비례합니다. 

켤레분포로 정규분포를 선택하였기 때문에 사후분포 역시 정규분포입니다. 

지수부에 대해 completing the square을 적용하고, 정규화된 정규 분포의 표준형태를 바탕으로 정규화 계수를 찾음으로써 사후분포를 구할 수 있습니다. 

실제로 적용해봅시다. 가능도함수는 다음과 같습니다. 

$p(t|\bold{X},w,\beta) = \prod_{n=1}^{N}\mathcal{N}(t_{n}|w^{T}\phi(\bold{x}_{n}),\beta^{-1})$

- 이는 각 데이터 포인트 $( t_n )$이 평균 $( w^T\phi(\bold{x}_n) )$과 분산 $( \beta^{-1} )$을 가지는 정규 분포를 따른다고 가정합니다. 

- 여기서 $( \phi(\bold{x}_n) )$는 $( \bold{x}_n )$에 대한 특징 변환(feature transformation)을 나타냅니다.

conjugate prior는 다음과 같이 정규분포로 주어졌습니다. 

- $p(w) = \mathcal{N}(w|m_{0},S_{0})$

- $m_{0}$,$S_{0}$ 는 각각 사전분포의 평균과 공분산 행렬을 말합니다. 
------------------------------------------------------------------------
이제 w에 대한 사후분포를 구합시다. 

$p(w|\bold{X},t,\beta)=\frac{p(t|\bold{X},w,\beta)p(w)}{p(t|X,\beta)}$


$p(w|\bold{X},t,\beta) \propto p(t|\bold{X},w,\beta)p(w)$

가능도와 사전분포의 곱을 $p(t|\bold{X},w,\beta) = \prod_{n=1}^{N}\mathcal{N}(t_{n}|w^{T}\phi(\bold{x}_{n}),\beta^{-1})$ 라고 했으므로, conjugeate distribution을 이용하면 다음과 같이 식을 고칠 수 있습니다.

$p(t|\bold{X},w,\beta)p(w) = \prod_{n=1}^{N}\mathcal{N}(t_{n}|w^{T}\phi(\bold{x}_{n}),\beta^{-1})\times \mathcal{N}(w|m_{0},S_{0})$

이제 $\prod_{n=1}^{N}\mathcal{N}(t_{n}|w^{T}\phi(\bold{x}_{n}),\beta^{-1})\times \mathcal{N}(w|m_{0},S_{0})=\mathcal{N}(w|m_{N},S_{N})$ 임을 보이면 됩니다. 

계산의 편리를 위해 log를 씌우겠습니다. 이를 통해 product가 summation으로 바뀝니다.

$log\sum_{n=1}^{N}\mathcal{N}(t_{n}|w^{T}\phi(\bold{x}_{n}),\beta^{-1}) + log\mathcal{N}(w|m_{0},S_{0})$

전반부와 후반부를 전개하여 각각 completing the square을 적용하여 정규분포의 형태로 만듭니다. 

$-\frac{\beta}{2}\sum_{n=1}^{N}(t_{n} - w^{T}\phi(x_{n}))^{2} -\frac{1}{2}(w-m_{0})^{T}S_{0}^{-1}(w-m_{0}) + const$

이 식을 이제 전개하면 다음과 같은 식으로 바뀝니다. 

$-\frac{\beta}{2}(w^{T}\Phi^{T}\Phi w -2w^{T}\Phi^{T}t + t^{T}t) -\frac{1}{2}(w-m_{0})^{T}S_{0}^{-1}(w-m_{0}) + const$

이 식을 다시 정규분포의 형태로 고칩니다. 

$-\frac{\beta}{2}(w - (S_{0}^{-1}m_{0}+\beta\Phi^{T}t)S_{0}^{-1}\beta\Phi^{T}\Phi(S_{0}^{-1}m_{0}+\beta\Phi^{T}t))+const$

이제 아래를 도출할 수 있습니다.

$$
\begin{align*}
&p(w|\bold{x},t,\alpha,\beta) = \mathcal{N}(w|m_{N},s_{N}),\\
&\text{where} \left\{\begin{matrix}
m_{N}=S_{N}(S_{0}^{-1}m_{0}+\beta\Phi^{T}t) \\
S_{N} = S_{0}^{-1} + \beta\Phi^{T}\Phi
\end{matrix}\right.
\end{align*}
$$
---------------------------------------------------------------------------------
이제 새로운 입력 $\bold{x}$에 대한 예측분포(predictive distribution)를 구해보겠습니다. 

예측분포를 구하는 일반적인 식은 아래와 같습니다. 

$$p(t|x,\bold{x},t)=\int p(t|x,w)p(w|x,t)dw$$

이 식을 구성하는 성분 중, 사후분포에 대해서는 앞서 구했습니다. 이는 가우시안 분포의 꼴로 나타났죠.

$p(w|x,t)=\mathcal{N}(w|m_{N},s_{N})$

이 식은 두 가우시안 분포의 convolution을 포함하고 있습니다. 따라서 가우시안 분포의 주변분포에 대한 공식 $p(y)=\mathcal{N}(y|A\mu + b, L^{-1} + A\Lambda^{-1}A^{T})$ 를 이용하면 예측분포의 형태를 구할 수 있습니다. 

$p(t|x,t,\alpha, \beta) =\int \mathcal{N}(t|\phi(x)^{T}w, \beta^{-1})\mathcal{N}(w|m_{N},S_{N})dw$

$=\mathcal{N}\left(t|\underset{m(x)}{\underbrace{\phi(x)^{T}m_{N}}}, \underset{s^{2}x}{\underbrace{\beta^{-1} + \phi(x)^{T}S_{N}\phi(x)}}\right)$


# 2. Programming

- Objective: To understand the differences among maximum likelihood estimation (MLE),
maximum a posterior (MAP), and fully Bayesian approach in regression

- Goal: To write computer programs of MLE, MAP, and Bayesian methods for predicting
a continuous target variable t for a test sample x

- Detailed descriptions
  - Let us limit the input space x in the range of [−1, 1].
  - Generate 100 i.i.d. sample points, $\left\{(x_{n}, t_{n})\right\}_{n=1}^{100}$,from a function $cos(2πx_{n}) +sin (πx_{n})$ with a random noise $ϵ ∼ N(0, β^{−1})$, where β = 11.1 fixed:

$$t_{n} = cos (2πx_{n}) + sin (πx_{n}) + ϵ.$$

  - Use a 9-th order polynomial function defined as follows:

$$y (x, w) = \sum_{j=1}^{9}w_{j}x^{j} + w_{0}.$$

  - For both MAP and Bayesian, use a prior distribution over w as $p (w|α) ∼ \mathcal{N}(0, α^{−1}I)$, where $α = 5 × 10^{−3}$ fixed.

- Requirements
  - Submission: a zipped file including your python codes and a short description on how to run your program in a markdown file (*.md)
  - The main function should take an input value of x for testing.
  - For the Bayesian method, it should display the predicted target value along with ±1 standard deviation in a graph.


  # How to use the code

  1. Make sure python is Installed and library matplotlib so. 
  2. Run the program in python environment.

```python
python3 Linear_regression_method.py
```