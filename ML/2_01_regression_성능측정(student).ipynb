{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxynTFaVH-Dg"
      },
      "source": [
        "#  Metirc\n",
        "- 모델 성능 평가지표\n",
        "- 실제값과 모델에 의해 예측된 값을 비교하여 모델의 성능을 측정\n",
        "- 모델 평가 목적\n",
        "    - 최적의 모델을 찾기 위해"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0QcGky7Hijj"
      },
      "source": [
        "- 회귀 문제 성능측정\n",
        "    - 실제값과 예측값의 차이를 측정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRHt3DlIJLS_"
      },
      "source": [
        "# 회귀 문제 성능측정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jB5Vb-3JhQ3"
      },
      "source": [
        "## 당뇨병 진행 예측\n",
        "- 당뇨병 진행도를 예측하는 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.2.0-cp311-cp311-win_amd64.whl (8.2 MB)\n",
            "     ---------------------------------------- 8.2/8.2 MB 35.0 MB/s eta 0:00:00\n",
            "Collecting numpy>=1.17.3\n",
            "  Downloading numpy-1.24.0-cp311-cp311-win_amd64.whl (14.8 MB)\n",
            "     --------------------------------------- 14.8/14.8 MB 50.3 MB/s eta 0:00:00\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.9.3-cp311-cp311-win_amd64.whl (39.9 MB)\n",
            "     --------------------------------------- 39.9/39.9 MB 27.3 MB/s eta 0:00:00\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "     ---------------------------------------- 298.0/298.0 kB ? eta 0:00:00\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
            "Successfully installed joblib-1.2.0 numpy-1.24.0 scikit-learn-1.2.0 scipy-1.9.3 threadpoolctl-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzZItA4NJwku",
        "outputId": "e1ee86a4-5454-4ee9-8a08-94f71a532619"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990749, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06833155, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286131, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04688253,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452873, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00422151,  0.00306441]]),\n",
              " array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "diabetes = load_diabetes()\n",
        "diabetes.data, diabetes.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TCPF4b-dHijm"
      },
      "outputs": [],
      "source": [
        "data=diabetes.data\n",
        "target=diabetes.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(442,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.0\n",
            "346.0\n"
          ]
        }
      ],
      "source": [
        "print(target.min())\n",
        "print(target.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY9EtUR6Jw9f"
      },
      "source": [
        "## 학습셋과 검증셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Hw5WIhyxHijm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_valid,y_train,y_valid=train_test_split(data,target,test_size=0.2)\n",
        "#sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
        "#xtrain,xvalid,ytrain,yvalid 순서입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MATRDq0NJxEF"
      },
      "source": [
        "## Linear Regression 모델을 이용한 학습 및 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3iRy7SpBJxG-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "model=LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_valid_predict=model.predict(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([235.36654465, 111.44604079,  46.18907786, 266.25848578,\n",
              "       123.71262787, 201.70016257, 145.71787655, 132.65689837,\n",
              "       242.07494132, 194.8787345 , 177.48090607, 259.4067687 ,\n",
              "       158.06251996, 131.69071088, 130.43457901,  76.20224144,\n",
              "       226.44444681, 105.29326073, 155.15360965,  90.71478392,\n",
              "        57.89201686, 126.53496411,  58.67267421,  66.92193769,\n",
              "       148.12774579, 151.89781084, 152.4935812 , 237.46969516,\n",
              "       268.31839795,  81.17834811,  96.08901605, 103.39440898,\n",
              "       187.68924446, 127.07755187, 179.76149454, 205.38433299,\n",
              "       194.35271092, 157.4316772 , 182.9481774 , 141.4396194 ,\n",
              "        92.48682628, 180.34614226,  85.41188426, 103.4583333 ,\n",
              "       192.91563351, 176.87844901, 190.17035896,  98.72567903,\n",
              "        43.20932591, 169.05100251, 203.73603527, 147.53887669,\n",
              "        69.32900521, 199.66387861, 164.20141181, 254.72357256,\n",
              "       189.22605214, 127.5987153 ,  75.8931169 , 145.00050077,\n",
              "       161.29114568, 132.7135107 , 118.6870092 , 157.3924243 ,\n",
              "        69.41959994, 124.08733953,  53.64821382, 149.93505348,\n",
              "       174.63927237,  98.02273219, 102.88367403, 184.56348799,\n",
              "        88.88016795, 147.51722407, 121.59409959, 128.19758671,\n",
              "       185.49207756, 137.55978966, 240.93811638, 125.12235727,\n",
              "       105.53324968, 158.76328845, 230.41912471, 165.09225908,\n",
              "        74.34878031, 143.6726518 , 187.21658619, 110.69090491,\n",
              "       155.63262317])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_valid_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmBGluARJxKF"
      },
      "source": [
        "## 회귀 평가 지표\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw3AXM2PJxMu"
      },
      "source": [
        "### MSE(Mean Squared Error)\n",
        "$$\n",
        "MSE = \\frac{1}{n}{\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2}\n",
        "$$\n",
        "- 실제값과 예측값의 차이를 제곱해서 평균화\n",
        "- 이상치에 민감\n",
        "- 직관적이지 못하다.\n",
        "- 손실함수로 주로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_bWuiAQiOwhu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3716.867098010312\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mse=mean_squared_error(y_valid,y_valid_predict)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFBJykWgJxPA"
      },
      "source": [
        "### RMSE(Root Mean Squared Error)\n",
        "$$\n",
        "RMSE = \\sqrt{\\frac{1}{n}{\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2}}\n",
        "$$\n",
        "- MSE에 루트\n",
        "- 이상치 민감\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwJb8aQGPIp5",
        "outputId": "37268926-932e-40ad-8fe4-39b4d1d43077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60.96611434239771\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 방법1\n",
        "import numpy as np\n",
        "np.sqrt(mse)\n",
        "\n",
        "# 방법2\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
        "rmse=mean_squared_error(y_valid,y_valid_predict,squared=False)\n",
        "print(rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFZvZV8qJxQ-"
      },
      "source": [
        "### MAE(Mean Absolute Error)\n",
        "$$\n",
        "MAE = \\frac{1}{n}{\\sum_{i=1}^{n}|y_i-\\hat{y}_i|}\n",
        "$$\n",
        "- 실제값과 예측값의 차이를 절대값으로 변환해서 평균화\n",
        "- 직관적이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUs37l6AJxTe",
        "outputId": "c93314fc-2890-4fe2-a390-6eb17eeab625"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49.99894763792065"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_valid,y_valid_predict)\n",
        "mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEY4Rv2uJxVN"
      },
      "source": [
        "### MAPE (Mean Absolute Percentage Error)\n",
        "$$\n",
        "MAPE = \\frac{100}{n}{\\sum_{i=1}^{n}\\frac{|y_i-\\hat{y}_i|}{y_i}}\n",
        "$$\n",
        "- 실제값에 대한 절대오차 비율의 평균을 퍼센트로 표현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNRj-Y6XJxXF",
        "outputId": "c349c648-1303-4f60-f434-cfc3d1fe56ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4883131513947471"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# 방법1\n",
        "def mape(true,pred):\n",
        "   return np.mean(np.abs((true - pred) / true))\n",
        "mape(y_valid,y_valid_predict)\n",
        "\n",
        "# 방법2\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "mean_absolute_percentage_error(y_valid, y_valid_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVHO-5UZRMgj"
      },
      "source": [
        "### SMAPE (Symmetric Mean Absolute Percentage Error)\n",
        "$$\n",
        "SMAPE = \\frac{100}{n}{\\sum_{i=1}^{n}\\frac{|y_i-\\hat{y_i}|}{{|y_i|}+|\\hat{y_i}|}}\n",
        "$$\n",
        "- 기존 mape의 단점을 보완한것\n",
        "- MAPE와 다른점은 각 실제값과 예측값을 절대값으로 변경후 핪으로 나눈다.\n",
        "- MAPE와 다르게 실제값에 0이 존재해도 계산이 가능하다.\n",
        "- 실제값보다 예측값이 크거나 작을수도있다.\n",
        "- 예측값이 실제값보다 작을때, 분모가 작아지기 때문에 오차가 커지게 된다. (과소추정에 대한 패널티가 줄수가 있다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Av88hkiOJDH",
        "outputId": "abea15ff-06a8-4b99-82e4-0663d5d8049d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.15271360402048711"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def smape(true,pred):\n",
        "   error =  np.abs(true - pred) / (np.abs(true) + np.abs(pred))\n",
        "   return np.mean(error) # 퍼센트로 나타낼꺼면 100 곱해주면됨\n",
        "smape(y_valid,y_valid_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 결정계수 R2 \n",
        "- 결정계수는 실제 관측값의 분산대비 예측값의 분산을 계산하여 데이터 예측의 정확도 성능을 측정하는 지표 \n",
        "- 0~1까지 수로 나타내어지며 1에 가까울수록 100%의 설명력을 가진 모델이라고 평가를 하게된다.\n",
        "- R^2 =1 : 현재 가지고 있는 X변수로 Y를 100% 설명. 즉, 모든 관측치가 회귀직선에 있다.\n",
        "- R^2 = 0 : 현재 가지고 있는 X변수는 Y 설명(예측)에 전혀 도움이 되지 않는다\n",
        "- 사용하고 있는 X변수의 품질\n",
        "- 변수가 많아지면 많아질수록 무조건 값이 올라감\n",
        "\n",
        "\n",
        "$$\n",
        "R^2 = \\frac{SSR}{SST} =\\frac{오차^2}{편차^2} =  1- \\frac{SSE}{SST}\n",
        "$$\n",
        "\n",
        "- SST (Sum of Squared Total): 관측치 - 예측평균값\n",
        "$$\n",
        "{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}\n",
        "$$\n",
        "- SSE (Sum of Squared Error): 관측값 - 예측값, 즉 잔차제곱합 RSS와 같은 의미이다.\n",
        "$$\n",
        "{\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2}\n",
        "$$\n",
        "- SSR (Sum of Squares due to Regression): 예측값 - 예측평균값\n",
        "$$\n",
        "{\\sum_{i=1}^{n}(\\hat{y_i}-\\bar{y})^2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.35017023542175296"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_valid, y_valid_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## adjusted R square\n",
        "![crash](https://i.stack.imgur.com/fLrDw.png)\n",
        "\n",
        "- adjusted r square \n",
        "- p=독립변수의 개수 \n",
        "- p가 분모에 위치하면서 p가 증가함에 따라 분자에 있는 rsquare의 증가영향을 어느 정도 상쇄해줌.\n",
        "- adj rsquare은 따라서 rsquare 보다 작음"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "73f2c00b3cc59b05db074228c29991fbacf0e1e6d0adc4f86a80a564870f5f16"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
