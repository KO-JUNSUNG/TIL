{"cells":[{"cell_type":"markdown","metadata":{"id":"g63soNOvFUSa"},"source":["# 서포트 벡터 머신(Support Vector Machines)"]},{"cell_type":"markdown","metadata":{"id":"Rrbp02Mk5CDA"},"source":["- 회귀, 분류, 이상치 탐지 등에 사용되는 지도학습 방법\n","- 클래스 사이의 경계에 위치한 데이터 포인트를 서포트 벡터(support vector)라고 한다.\n","- 각 지지 벡터가 클래스 사이의 결정 경계를 구분하는데 얼마나 중요한지를 학습\n","- 각 지지 벡터 사이의 마진이 가장 큰 방향으로 학습\n","- 지지 벡터 까지의 거리와 지지 벡터의 중요도를 기반으로 예측을 수행\n","\n","![support vector machine](https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/Svm_separating_hyperplanes.png/220px-Svm_separating_hyperplanes.png)\n","\n","- H3은 두 클래스의 점들을 제대로 분류하고 있지 않음\n","- H1과 H2는 두 클래스의 점들을 분류하는데, H2가 H1보다 더 큰 마진을 갖고 분류하는 것을 확인할 수 있음"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671762572397,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"zBilnkAn4_U3"},"outputs":[],"source":["import multiprocessing\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use(['seaborn-whitegrid'])"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1665,"status":"ok","timestamp":1671762680169,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"1YRJRPy6hTe0"},"outputs":[],"source":["from sklearn.svm import SVR, SVC # SVC  classification, SVR regression\n","from sklearn.datasets import load_boston, load_diabetes\n","from sklearn.datasets import load_breast_cancer, load_iris, load_wine\n","from sklearn.pipeline import make_pipeline, Pipeline\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.manifold import TSNE # 원래 데이터를 2차원으로 축소, 주로 시각화에 활용된다. "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1671762761456,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"PfSHJ7350qDZ"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"UxS0mPsCh4l0"},"source":["## SVM을 이용한 회귀 모델과 분류 모델"]},{"cell_type":"markdown","metadata":{"id":"NTtcx3p8wtNX"},"source":["### SVM을 사용한 회귀 모델 (SVR)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1671762765556,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"sCrhSrMf5BqB","outputId":"7c07dd1c-4df1-499c-e9ee-050957f55eb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Data Score: 0.2177283706374875\n","Test Data Score: 0.13544178468518187\n"]}],"source":["x, y = load_boston(return_X_y=True)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=123)\n","\n","model = SVR()\n","model.fit(x_train, y_train)\n","\n","print(f'Train Data Score: {model.score(x_train, y_train)}')\n","print(f'Test Data Score: {model.score(x_test, y_test)}')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671762884733,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"TgU3GMVn0mNL"},"outputs":[],"source":["model?\n","# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"]},{"cell_type":"markdown","metadata":{"id":"CQraX6MzwvtE"},"source":["### SVM을 사용한 분류 모델 (SVC)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1671762918707,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"bnh5fS8gFbtK","outputId":"4f7f2572-d1e1-4718-92de-48777d8ad69e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Data Score: 0.9014084507042254\n","Test Data Score: 0.9230769230769231\n"]}],"source":["x, y = load_breast_cancer(return_X_y=True)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=123)\n","\n","model = SVC()\n","model.fit(x_train, y_train)\n","\n","print(f'Train Data Score: {model.score(x_train, y_train)}')\n","print(f'Test Data Score: {model.score(x_test, y_test)}')"]},{"cell_type":"markdown","metadata":{"id":"zgd_dvKrGeFh"},"source":["## 커널 기법\n","\n","- 입력 데이터를 고차원 공간에 사상해서 비선형 특징을 학습할 수 있도록 확장하는 방법\n","- scikit-learn에서는 Linear, Polynomial, RBF(Radial Basis Function)등 다양한 커널 기법을 지원"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mN3A99DhzxqV"},"outputs":[],"source":["# load_boston 보스턴 집값"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2675,"status":"ok","timestamp":1671762975894,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"Azq1UJtZF8sU","outputId":"ce0a5492-0141-45ff-a229-f9c9b1ec0aed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear SVR Train Data Score: 0.715506620496448\n","Linear SVR Test Data Score: 0.6380398541506058\n","Polynomial SVR  Train Data Score: 0.2024454261446289\n","Polynomial SVR Test Data Score: 0.133668450367462\n","RBF SVR Train Data Score: 0.2177283706374875\n","RBF SVR Test Data Score: 0.13544178468518187\n"]}],"source":["x, y = load_boston(return_X_y=True)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=123)\n","\n","linear_svr = SVR(kernel = 'linear')\n","linear_svr.fit(x_train, y_train)\n","\n","print(f'Linear SVR Train Data Score: {linear_svr.score(x_train, y_train)}')\n","print(f'Linear SVR Test Data Score: {linear_svr.score(x_test, y_test)}')\n","\n","polynomial_svr = SVR(kernel = 'poly')\n","polynomial_svr.fit(x_train, y_train)\n","\n","print(f'Polynomial SVR  Train Data Score: {polynomial_svr.score(x_train, y_train)}')\n","print(f'Polynomial SVR Test Data Score: {polynomial_svr.score(x_test, y_test)}')\n","\n","rbf_svr = SVR(kernel = 'rbf')\n","rbf_svr.fit(x_train, y_train)\n","\n","print(f'RBF SVR Train Data Score: {rbf_svr.score(x_train, y_train)}')\n","print(f'RBF SVR Test Data Score: {rbf_svr.score(x_test, y_test)}')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671763138918,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"zzUItg9E1-Qg","outputId":"de7804e0-87bc-4d25-f4bb-b9dfa96031be"},"outputs":[{"data":{"text/plain":["68.25016057501936"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import mean_squared_error\n","mean_squared_error(y_test, rbf_svr.predict(x_test))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1671763666971,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"LQV7id4_zxqW","outputId":"edcc803d-abb8-409c-fd12-9b07c2d5a000"},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear SVC Train Data Score: 0.960093896713615\n","Linear SVC Test Data Score: 0.986013986013986\n","Polynomial SVC Train Data Score: 0.9014084507042254\n","Polynomial SVC Test Data Score: 0.9230769230769231\n","RBF SVC Train Data Score: 0.9014084507042254\n","RBF SVC Test Data Score: 0.9230769230769231\n"]}],"source":["# 유방암 데이터를 이용한 분류\n","# - 각 커널별로 유방암 데이터를 분류해보자. \n","# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","\n","X, y = load_breast_cancer(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n","\n","linear_svc = SVC(kernel = 'linear')\n","linear_svc.fit(X_train, y_train)\n","\n","print(f'Linear SVC Train Data Score: {linear_svc.score(X_train, y_train)}')\n","print(f'Linear SVC Test Data Score: {linear_svc.score(X_test, y_test)}')\n","\n","polynomial_svc = SVC(kernel = 'poly')\n","polynomial_svc.fit(X_train, y_train)\n","\n","print(f'Polynomial SVC Train Data Score: {polynomial_svc.score(X_train, y_train)}')\n","print(f'Polynomial SVC Test Data Score: {polynomial_svc.score(X_test, y_test)}')\n","\n","rbf_svc = SVC(kernel = 'rbf')\n","rbf_svc.fit(X_train, y_train)\n","\n","print(f'RBF SVC Train Data Score: {rbf_svc.score(X_train, y_train)}')\n","print(f'RBF SVC Test Data Score: {rbf_svc.score(X_test, y_test)}')\n","\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":255,"status":"ok","timestamp":1671763541473,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"V-zjpdlg29ZA"},"outputs":[],"source":["# 참고 https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-3-7-%EC%BB%A4%EB%84%90-%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0/"]},{"cell_type":"markdown","metadata":{"id":"ysbUu5o3Lm2V"},"source":["## 매개변수 튜닝\n","\n","- SVM은 사용하는 커널에 따라 다양한 매개변수 설정 가능\n","- 매개변수를 변경하면서 성능변화를 관찰\n","\n"," - C는 얼마나 많은 데이터 샘플이 다른 클래스에 놓이는 것을 허용하는지를 결정\n","  - 작을 수록 많이 허용하고, 클 수록 적게 허용한다.\n","  -  C값을 낮게 설정하면 이상치들이 있을 가능성을 크게 잡아 일반적인 결정 경계를 찾아내고, 높게 설정하면 반대로 이상치의 존재 가능성을 작게 봐서 좀 더 세심하게 결정 경계를 찾아낸다.\n","\n","  - [참고](https://bskyvision.com/entry/%EC%84%9C%ED%8F%AC%ED%8A%B8-%EB%B2%A1%ED%84%B0-%EB%A8%B8%EC%8B%A0SVM%EC%9D%98-%EC%82%AC%EC%9A%A9%EC%9E%90%EB%A1%9C%EC%84%9C-%EA%BC%AD-%EC%95%8C%EC%95%84%EC%95%BC%ED%95%A0-%EA%B2%83%EB%93%A4-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98-C%EC%99%80-gamma)\n","\n","\n","|파라미터|default\t| 설명|\n","|-------|-------|-------|\n","|C\t|1.0|\t오류를 얼마나 허용할 것인지 (규제항) 클수록 하드마진, 작을수록 소프트마진에 가까움|\n","|kernel\t|'rbf' (가우시안 커널)| 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'|\n","|degree\t| 3| \t다항식 커널의 차수 결정 |\n","|gamma\t|'scale'|\t결정경계를 얼마나 유연하게 그릴지 결정 클수록 오버피팅 발생 가능성 높아짐|\n","|coef0\t|0.0\t|다항식 커널에 있는 상수항 r"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1671768704265,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"JyCxM4abOZyO"},"outputs":[],"source":["x, y = load_breast_cancer(return_X_y=True)\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=123)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21109,"status":"ok","timestamp":1671768733009,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"QN4BSxiaJspb","outputId":"6b7c9234-f41e-452a-ff77-ed76889d300b"},"outputs":[{"name":"stdout","output_type":"stream","text":["kernel=ploy, degree=2, C=0.1, gamma=auto\n","Polynomial SVC Train Data Score: 0.9835680751173709\n","Polynomial SVC Test Data Score: 0.993006993006993\n"]}],"source":["polynomial_svc = SVC(kernel = 'poly', degree=2, C=0.1, gamma='auto')\n","polynomial_svc.fit(x_train, y_train)\n","\n","print(f'kernel=ploy, degree={2}, C={0.1}, gamma={\"auto\"}')\n","print(f'Polynomial SVC Train Data Score: {polynomial_svc.score(x_train, y_train)}')\n","print(f'Polynomial SVC Test Data Score: {polynomial_svc.score(x_test, y_test)}')"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1671768851110,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"P7hOhO1oOvVC","outputId":"3dc24d60-5d46-4f2c-cc42-04ad3dd1e567"},"outputs":[{"name":"stdout","output_type":"stream","text":["kernel=ploy, C=2.0, gamma=scale\n","RBF SVC Train Data Score: 0.9154929577464789\n","RBF SVC Test Data Score: 0.9370629370629371\n"]}],"source":["rbf_svc = SVC(kernel = 'rbf', C=2.0, gamma='scale')\n","rbf_svc.fit(x_train, y_train)\n","\n","print(f'kernel=ploy, C={2.0}, gamma={\"scale\"}')\n","print(f'RBF SVC Train Data Score: {rbf_svc.score(x_train, y_train)}')\n","print(f'RBF SVC Test Data Score: {rbf_svc.score(x_test, y_test)}')"]},{"cell_type":"markdown","metadata":{"id":"aEQL8h8WU0An"},"source":["## 데이터 전처리\n","\n","- SVM은 입력 데이터가 정규화 되어야 좋은 성능을 보임\n","- 주로 모든 특성 값을 [0, 1] 범위로 맞추는 방법을 사용\n","- scikit-learn의 StandardScaler 또는 MinMaxScaler를 사용해 정규화"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gyou-F_XzxqZ"},"outputs":[],"source":["# 예 load_breast_cancer 데이터를 StandardScaler 를 이용해 정규화 하고 학습시켜보자\n","# - Score 는?\n","\n","# model 생성\n","# 그냥 학습  vs StandardScaler 로 데이터 변환후 학습 vs MinMaxScaler 로 변환후 학습 \n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1671769668906,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"FJeKasUaM970","outputId":"b2f8b2e5-a9ea-42b0-dee9-a8fc244fd5f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["SVC Train Data Score: 0.9014084507042254\n","SVC Test Data Score: 0.9230769230769231\n"]}],"source":["model = SVC()\n","model.fit(X_train, y_train)\n","\n","print(f'SVC Train Data Score: {model.score(X_train, y_train)}')\n","print(f'SVC Test Data Score: {model.score(X_test, y_test)}')"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":712,"status":"ok","timestamp":1671769686488,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"bkLC-8rQNAhS","outputId":"8c2a49f3-95dd-46bd-e247-c2d100844721"},"outputs":[{"name":"stdout","output_type":"stream","text":["SVC Train Data Score: 0.9835680751173709\n","SVC Test Data Score: 0.986013986013986\n"]}],"source":["scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)\n","\n","model = SVC()\n","model.fit(X_train, y_train)\n","\n","print(f'SVC Train Data Score: {model.score(X_train, y_train)}')\n","print(f'SVC Test Data Score: {model.score(X_test, y_test)}')"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1671769704471,"user":{"displayName":"강의","userId":"06095034021433233068"},"user_tz":-540},"id":"48w3EQn5NJr8","outputId":"936d7fca-dbcf-4e12-c208-964727f4ec57"},"outputs":[{"name":"stdout","output_type":"stream","text":["SVC Train Data Score: 0.9812206572769953\n","SVC Test Data Score: 0.9300699300699301\n"]}],"source":["scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)\n","\n","model = SVC()\n","model.fit(X_train, y_train)\n","\n","print(f'SVC Train Data Score: {model.score(X_train, y_train)}')\n","print(f'SVC Test Data Score: {model.score(X_test, y_test)}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- 최적화 식의 결정변수(Descision Variable)은 W와 b(=w_0)를 찾는것.\n","- 목적식(Object Function)은 Seperating Hyper Plane으로 부터 정의된 Margin의 역수라 할수 있다.\n","- 제약식(Constraint)는 Training Data를 완벽하게 분리 하는 조건을 갖어야 한다.\n","- Object function은 2차식(Quadratic) 그리고 제약식은 선형(Linear) 이기 때문에 2차 계획법(Quadratic Programming)을 사용하여 문제를 해결한다.\n","- ⇒ Convex OPtimization (2차 곡선의 최적화 문제) ⇒ Globally Optimal Solution Exist (전역해 존재)  즉, 2차식의 연립방정식의 최적해이기 때문에 전역해가 존재한다.\n","\n","- 결론\n","1. 라그랑지 승수를 이용한 최적화 기법 사용\n","2. 라그랑지 승수는 제약이 있는 최적화 문제를 해결하는 방법이다.\n","3. 최적화 하려는 값에 라그랑지 승수라는 형식적인 값을 더하여 제약된 문제를 제약없는 문제로 변경\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_psU23RzPUMe"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1tTbmeS0Bp0_NkFDsT1DvwvnRjkZUY9Yz","timestamp":1632747262302}]},"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"73f2c00b3cc59b05db074228c29991fbacf0e1e6d0adc4f86a80a564870f5f16"}}},"nbformat":4,"nbformat_minor":0}
