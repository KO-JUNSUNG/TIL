{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y8AwKGB8-Mo"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_S-IHD88-My"
      },
      "source": [
        "# Training a Neural Network\n",
        "\n",
        "## Softmax 층\n",
        "\n",
        "$$y_i = \\text{Softmax}(z_i) = \\dfrac{\\exp(z_i)}{\\sum_j^k \\exp(z_j)}$$\n",
        "\n",
        "`torch.softmax` 를 사용하면 함수처럼 사용할 수 있고, `nn.Softmax()`를 사용해서 객체 생성 후 하나의 층 처럼 사용할 수도 있다. 다만 Softmax 할 차원을 지정해줘야한다.\n",
        "\n",
        "* PyTorch Docs: [softmax](https://pytorch.org/docs/stable/nn.html#softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVQIuRac8-Mz",
        "outputId": "1674ac04-47ab-47ea-e4f4-4a61771d5cee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.FloatTensor([3, 1, 5, 9])\n",
        "prob = torch.softmax(x, dim=0)\n",
        "print(f\"{prob.numpy().round(3)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.002 0.    0.018 0.979]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBNosEXf8-M4",
        "outputId": "f655a778-dcd3-42d5-a926-14f8955f35ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "softmax_layer = nn.Softmax(dim=1)\n",
        "x = torch.FloatTensor([[3, 1, 5, 9], \n",
        "                       [4, 6, 5, 3]])\n",
        "print(x.size())\n",
        "prob = softmax_layer(x)\n",
        "print(f\"{prob.numpy().round(3)}\\n\")\n",
        "print(f\"dim=1 으로 합을 하면 1이 된다: {prob.sum(1)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "[[0.002 0.    0.018 0.979]\n",
            " [0.087 0.644 0.237 0.032]]\n",
            "\n",
            "dim=1 으로 합을 하면 1이 된다: tensor([1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0yOAcOq8-M8"
      },
      "source": [
        "보통 softmax의 0에 가까운 아주 작은 수라서 log를 취해서 `torch.log_softmax`를 사용한다(혹은 `nn.LogSoftmax`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77lk2P_A8-M-",
        "outputId": "4fed1ddc-541c-471c-8159-cc2aa1ced0c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.0209, -8.0209, -4.0209, -0.0209],\n",
              "        [-2.4402, -0.4402, -1.4402, -3.4402]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWG4Ba_w8-NA"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "XOR 문제는 0과 1 두 가지 클래스를 분류하는 문제다. Cross-Entropy 를 사용할 수 있다. \n",
        "\n",
        "따라서 네트워크의 마지막 층을 2개로 출력하고 `Softmax` 층을 넣어야 한다. 다만 PyTorch의 Cross Entropy Loss(`nn.CrossEntropyLoss`)에는 `LogSoftmax`가 포함되어 있어서 넣지 않아도 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH9rDNAO8-NB"
      },
      "source": [
        "torch.manual_seed(70)\n",
        "\n",
        "class XOR(nn.Module):\n",
        "    \"\"\"XOR Network\"\"\"\n",
        "    def __init__(self):\n",
        "        super(XOR, self).__init__()\n",
        "        # 층을 구성\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 3),  # in_features, out_features\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(3, 2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(2, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # forward propagation 수행\n",
        "        o = self.layers(x)\n",
        "        return o\n",
        "    \n",
        "    def predict(self, x):\n",
        "        o = self.forward(x)\n",
        "        y = torch.softmax(o, dim=1)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6oQLEtT8-ND",
        "outputId": "72528a74-cebf-4911-ce55-d86fb12d8289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 입력텐서 타겟 텐서 생성    \n",
        "x = torch.Tensor([[0, 1]])\n",
        "t = torch.LongTensor([0])\n",
        "\n",
        "# 커스텀 모듈 호출\n",
        "model = XOR()\n",
        "\n",
        "# 손실함수\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# 순방향전파\n",
        "y = model(x) # 입력 x를 넣었을 때, 모델이 출력하는 값\n",
        "\n",
        "# 손실값 계산\n",
        "loss = loss_function(y, t)\n",
        "\n",
        "print(f\"loss value: {loss.item()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss value: 0.3809916377067566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbK-35a18-NE"
      },
      "source": [
        "## nn.AutoGrad\n",
        "\n",
        "PyTorch의 AutoGrad는 Tensor의 미분 자동화를 돕는 패키지다. 각 텐서에는 `requires_grad`라는 속성이 있어서 미분이 필요한 텐서인지 아닌지 확인할 수 있다. 또한 `requires_grad_` 함수를 호출하면 해당 텐서는 미분이 필요한 텐서가 되며, 역전파시 미분을 계산하게 된다.\n",
        "\n",
        "* 함수뒤에 \"\\_\" 표시는 in-place operations 으로써 실행하면 새로운 메모리에 할당하지 않고, 메모리를 차지하고 있는 텐서에 덮어쓰는 형식이다. PyTorch에서는 사용을 권장하고 있지 않다. [관련 링크](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2oldEG48-NF",
        "outputId": "9efbce5c-1c14-4044-b600-9a8d908c639b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.FloatTensor([10])\n",
        "\n",
        "print(f\"require gradient? {x.requires_grad}\")\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "# requires_grad\n",
        "x.requires_grad_(True)\n",
        "# '_' x의 특성을 바꾼다.\n",
        "print(f\"require gradient? {x.requires_grad}\")\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "require gradient? False\n",
            "tensor([10.])\n",
            "\n",
            "require gradient? True\n",
            "tensor([10.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qNCzQ058-NG"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1SPGm636Na_VrRTHkcBhMOQGMq0CaYAtg\" width=\"640px\" >\n",
        "\n",
        "예제로 계산 그래프를 그려본다.\n",
        "\n",
        "$$\\begin{aligned}\n",
        "c(a, b) &= a + b\\\\\n",
        "d(b) &= 2\\times b + 1\\\\\n",
        "e(c, d) &= c\\times d \n",
        "\\end{aligned} \\\\ \\ \\\\ \\text{where } a=2, b=3$$\n",
        "\n",
        "연산 경로에 미분이 필요한 텐서가 들어가면 자동으로 `requires_grad=True`가 된고, 연산이 진행된 텐서는 `grad_fn` 역전파 함수를 내포하고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBnrpYvl8-NH",
        "outputId": "ca05561f-63c1-48d1-be72-893d466e1c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = torch.FloatTensor([2]).requires_grad_()\n",
        "b = torch.FloatTensor([3])\n",
        "c = a + b\n",
        "d = 2 * b + 1\n",
        "e = c * d\n",
        "\n",
        "print(f\"require gradient?\")\n",
        "for t, name in zip([a, b, c, d, e], [\"a\", \"b\", \"c\", \"d\", \"e\"]):\n",
        "    print(f\"  - {name}(={t.item()}): {t.requires_grad} \\t/ grad_fn: \\t {t.grad_fn}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "require gradient?\n",
            "  - a(=2.0): True \t/ grad_fn: \t None\n",
            "  - b(=3.0): False \t/ grad_fn: \t None\n",
            "  - c(=5.0): True \t/ grad_fn: \t <AddBackward0 object at 0x7fb12ae10a90>\n",
            "  - d(=7.0): False \t/ grad_fn: \t None\n",
            "  - e(=35.0): True \t/ grad_fn: \t <MulBackward0 object at 0x7fb12ae10dc0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwNOexID8-NI"
      },
      "source": [
        "미분을 구하려면 `backward` 함수에 경사를 전달하면 된다. 각 텐서에서 `.grad` 속성을 조회하면 미분값을 확인할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GGcLcCv8-NJ",
        "outputId": "a0b25f49-8277-4ffb-bc8e-59c325badd55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gradient = torch.FloatTensor([1.])\n",
        "e.backward(gradient)\n",
        "\n",
        "print(f\"gradient\")\n",
        "for t, name in zip([a, b, c, d, e], [\"a\", \"b\", \"c\", \"d\", \"e\"]):\n",
        "    print(f\"  - {name}: {t.grad}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient\n",
            "  - a: tensor([7.])\n",
            "  - b: None\n",
            "  - c: None\n",
            "  - d: None\n",
            "  - e: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-c806ec9d3b09>:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(f\"  - {name}: {t.grad}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPOw-uLj8-NK"
      },
      "source": [
        "## torch.optim\n",
        "\n",
        "PyTorch의 최적화 관련된 것은 모두 optim 패키지에 있다. `model.parameters()`는 모델 안에 내포되있는 모든 파라미터를 `generator` 객체를 생성한다. 이를 옵티마이저에게 전달하여 업데이트할 매개변수를 등록한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFECmBIY8-NL"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 입력텐서 타겟 텐서 생성    \n",
        "x = torch.Tensor([[0, 1]])\n",
        "t = torch.LongTensor([0])\n",
        "\n",
        "# 커스텀 모듈 호출\n",
        "model = XOR()\n",
        "\n",
        "# 손실함수\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1) # 최적의 weight 찾아가는 방법\n",
        "\n",
        "# 순방향전파\n",
        "y = model(x)\n",
        "\n",
        "# 손실값 계산\n",
        "loss = loss_function(y, t)\n",
        "\n",
        "# 역전파\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zghElbf9Ojws",
        "outputId": "d77f748d-7a1a-4e52-8f44-a82e22fe71cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.5507,  0.5411],\n",
              "         [-0.0689,  0.2959],\n",
              "         [-0.5067, -0.2694]], requires_grad=True), Parameter containing:\n",
              " tensor([ 0.0109, -0.2710, -0.0036], requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.2411, -0.5309,  0.4952],\n",
              "         [ 0.3050,  0.1696,  0.1465]], requires_grad=True), Parameter containing:\n",
              " tensor([0.4334, 0.0564], requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.3373,  0.1327],\n",
              "         [-0.3907,  0.4640]], requires_grad=True), Parameter containing:\n",
              " tensor([ 0.2514, -0.6791], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhLKQW5N8-NM"
      },
      "source": [
        "옵티마이저의 `.step()` 함수를 호출하면 옵티마이저가 해당 매개변수를 업데이트 해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gBkbaoZ8-NN",
        "outputId": "0fef625d-b015-4d3c-8fd6-1c2d3bcadf57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "print(\"첫번째 Linear Layer Weight: \")\n",
        "print(model.layers[0].weight)\n",
        "print()\n",
        "print(\"첫번째 Linear Layer Weight의 Gradient: \")\n",
        "print(model.layers[0].weight.grad)\n",
        "print()\n",
        "\n",
        "optimizer.step() # 업데이트\n",
        "\n",
        "print(\"첫번째 Linear Layer Weight의 Gradient: \")\n",
        "print(model.layers[0].weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "첫번째 Linear Layer Weight: \n",
            "Parameter containing:\n",
            "tensor([[ 0.5068, -0.1696],\n",
            "        [-0.6171, -0.1940],\n",
            "        [-0.6448, -0.4407]], requires_grad=True)\n",
            "\n",
            "첫번째 Linear Layer Weight의 Gradient: \n",
            "tensor([[ 0.0000,  0.0022],\n",
            "        [ 0.0000,  0.0062],\n",
            "        [-0.0000, -0.0021]])\n",
            "\n",
            "첫번째 Linear Layer Weight의 Gradient: \n",
            "Parameter containing:\n",
            "tensor([[ 0.5068, -0.1698],\n",
            "        [-0.6171, -0.1946],\n",
            "        [-0.6448, -0.4405]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iUMmtfE8-NP"
      },
      "source": [
        "경사하강법 $$ W^{(1)}_{new} = W^{(1)}_{old} - \\alpha \\dfrac{\\partial L}{\\partial W^{(1)}}_{old}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAbvAt1G8-NP",
        "outputId": "7f6b8a1d-79f9-40a8-f9ea-7245d72e1681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\" w_22 의 파라미터 업데이트: w ={0.3146 - 0.1 * (0.0074): .4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " w_22 의 파라미터 업데이트: w = 0.3139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9icvchVQ8-NR"
      },
      "source": [
        "## XOR 문제 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTGvBbL-8-NR",
        "outputId": "4864cd6c-00ee-4204-a755-0e9df4919ac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.manual_seed(70)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # gpu 사용 여부\n",
        "n_step = 10000  # 총 학습 스텝 = epochs\n",
        "\n",
        "# Data 세트 만들기\n",
        "inputs = torch.FloatTensor([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
        "targets = torch.LongTensor([0, 1, 1, 0])\n",
        "\n",
        "# 모델 생성: gpu를 사용하려면 모델에도 device를 전달해준다.\n",
        "model = XOR().to(device)\n",
        "# 손실함수 정의\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# 옵티마이저 정의\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.7)\n",
        "\n",
        "# GPU를 사용하려면 입력 텐서에도 device를 전달해준다.\n",
        "inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "best_loss = 999\n",
        "# n_step 동안 학습을 진행한다.\n",
        "for step in range(n_step):\n",
        "    # -- 훈련단계 --\n",
        "    train_loss = 0\n",
        "    \n",
        "    # 매개변수 텐서의 grad 정보를 0으로 만든다. model.zero_grad() 로도 가능하다.\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 순방향전파(Forward Propagation)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Loss 계산\n",
        "    loss = loss_function(outputs, targets)\n",
        "    \n",
        "    # 역방향전파(Back Propagation)\n",
        "    loss.backward()\n",
        "    \n",
        "    # 옵티마이저로 매개변수 업데이트\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 훈련단계 손실값 기록(모든 데이터에 손실값의 평균을 합친다.)\n",
        "    train_loss += loss.item()\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        torch.save(model.state_dict(), \"./xor.pt\")\n",
        "    if step % 1000 == 0:\n",
        "        print(f\"[{step+1}] Loss: {train_loss:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Loss: 0.8337\n",
            "[1001] Loss: 0.6932\n",
            "[2001] Loss: 0.6932\n",
            "[3001] Loss: 0.6931\n",
            "[4001] Loss: 0.6931\n",
            "[5001] Loss: 0.6931\n",
            "[6001] Loss: 0.6931\n",
            "[7001] Loss: 0.6927\n",
            "[8001] Loss: 0.0309\n",
            "[9001] Loss: 0.0032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_2N_ZVORfXq",
        "outputId": "0c730afe-80f8-4db5-874c-c24609bf5fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "model.state_dict() # 모델의 저장정보를 확인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layers.0.weight', tensor([[ 1.2730,  0.5956],\n",
              "                      [-3.1124, -3.5019],\n",
              "                      [-5.5307, -5.3661]], device='cuda:0')),\n",
              "             ('layers.0.bias',\n",
              "              tensor([-0.6217,  4.9397,  2.0589], device='cuda:0')),\n",
              "             ('layers.2.weight', tensor([[-0.5659,  1.2677, -1.8566],\n",
              "                      [-2.8928,  6.1726, -7.4217]], device='cuda:0')),\n",
              "             ('layers.2.bias', tensor([-0.6035, -1.0970], device='cuda:0')),\n",
              "             ('layers.4.weight', tensor([[-1.1127, -6.9834],\n",
              "                      [ 0.8168,  8.1486]], device='cuda:0')),\n",
              "             ('layers.4.bias', tensor([ 3.9442, -4.0051], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BO5I8k8-NT"
      },
      "source": [
        "## 모델 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm5A45UJ8-NT",
        "outputId": "5363ce2e-16d6-4582-eded-b517715e5030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 새로 정의\n",
        "model = XOR()\n",
        "# 모델 불러오기\n",
        "model.load_state_dict(torch.load(\"./xor.pt\", map_location=\"cuda\"))\n",
        "\n",
        "probs = model.predict(inputs.cpu())\n",
        "print(probs)\n",
        "predicts = probs.argmax(1)\n",
        "print(predicts)\n",
        "for prob, pred in zip(probs, predicts):\n",
        "    print(f\"prob: {prob.data}\\t predict {pred}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9984, 0.0016],\n",
            "        [0.0015, 0.9985],\n",
            "        [0.0013, 0.9987],\n",
            "        [0.9977, 0.0023]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0, 1, 1, 0])\n",
            "prob: tensor([0.9984, 0.0016])\t predict 0\n",
            "prob: tensor([0.0015, 0.9985])\t predict 1\n",
            "prob: tensor([0.0013, 0.9987])\t predict 1\n",
            "prob: tensor([0.9977, 0.0023])\t predict 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9qRsgUhRrCj"
      },
      "source": [
        "# inputs = torch.FloatTensor([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
        "# targets = torch.LongTensor([0, 1, 1, 0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}