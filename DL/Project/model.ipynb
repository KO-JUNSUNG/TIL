{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 16:01:23.030359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 16:01:23.723966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/extras/CUPTI/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2023-02-02 16:01:23.726141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/extras/CUPTI/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2023-02-02 16:01:23.726152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "## import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2 \n",
    "# I made it.\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 전처리\n",
    "# 4개의 파일을 사용\n",
    "data_forward_woman = np.loadtxt(fileUrl + '/forward/data_forward_woman.csv', unpack = True, delimiter=',', skiprows = 1, dtype=np.int64)\n",
    "data_forward_man = np.loadtxt(fileUrl + '/forward/data_forward_man.csv', unpack = True, delimiter=',', skiprows = 1, dtype=np.int64)\n",
    "data_left_woman = np.loadtxt(fileUrl + '/left/data_left_woman.csv', unpack = True, delimiter=',', skiprows = 1, dtype=np.int64)\n",
    "data_left_man = np.loadtxt(fileUrl + '/left/data_left_man.csv', unpack = True, delimiter=',', skiprows = 1, dtype=np.int64)\n",
    "data_right_woman = np.loadtxt(fileUrl + '/left/data_right_woman.csv', unpack = True, delimiter=',', skiprows = 1, dtype=np.int64)\n",
    "data_right_man = np.loadtxt(fileUrl + '/left/data_right_man.csv', unpack = True, delimiter=',', skiprows = 1, dtype=np.int64)\n",
    "\n",
    "# 두 명의 서 있는 자세와 앉아 있는 자세 병합\n",
    "data_forward = np.concatenate((data_forward_woman, data_forward_man), axis = 1).transpose()\n",
    "data_left = np.concatenate((data_left_woman, data_left_man), axis = 1).transpose()\n",
    "data_right = np.concatenate((data_right_woman, data_right_man), axis = 1).transpose()\n",
    "\n",
    "# 분류를 위한 라벨 구성  0= forward, 1=left, 2=right\n",
    "label_forward = []\n",
    "label_left = []\n",
    "label_right = []\n",
    "for i in range(len(data_forward)):\n",
    "  label_forward.append(0)\n",
    "for i in range(len(data_left)):\n",
    "  label_left.append(1)\n",
    "for i in range(len(data_right)):\n",
    "  label_right.append(1)\n",
    "    \n",
    "\n",
    "# 앉아 있는 자세와 서 있는 자세에 대한 데이터를 합쳐서 데이터 전처리 마무리\n",
    "data = np.concatenate((data_forward, data_left, data_right), axis = 0)\n",
    "label = np.array(label_forward + label_left + label_right)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size = 0.2, random_state = 121)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3))) #BGR or RGB\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax')) # normal, or alert\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on your training data\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 2\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print('accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Maded_model.h5') #save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80cc27e9a0e8aa59b18a6f502b8a24c9fe77be3bcd87d0900d8763aa62f81a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
