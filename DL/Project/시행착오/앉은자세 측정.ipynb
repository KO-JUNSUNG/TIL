{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 15:56:45.287026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 15:56:46.697014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2023-02-02 15:56:46.698847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.2/extras/CUPTI/lib64:/usr/local/cuda-11.2/lib64:\n",
      "2023-02-02 15:56:46.698856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "from threading import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@7.352] global cap_v4l.cpp:982 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@7.352] global obsensor_uvc_stream_channel.cpp:156 getStreamChannelGroup Camera index out of range\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# import keyboard\n",
    "# 다른 프로그램에서 카메라를 사용하고 있으면 작동하지 않음.\n",
    "'''pip install keyboard'''\n",
    "# ==================================\n",
    "pose_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
    "             29, 30, 31, 32]\n",
    "timesout = 10\n",
    "Alert = -1\n",
    "status = -1\n",
    "timer_count = 0\n",
    "is_running = False\n",
    "is_timer_running = False\n",
    "\n",
    "\n",
    "# ==================================\n",
    "\n",
    "def is_turtleneck(ear, shoulder):\n",
    "    print(\">>거북목 검사하기<<\")\n",
    "    print(round(ear, 2), round(shoulder, 2))\n",
    "    turtleneck = shoulder * 0.19\n",
    "    if shoulder - turtleneck < ear:\n",
    "        print(\"거북목 아님\")\n",
    "    else:\n",
    "        print(\"거북목 의심해보시길...\")\n",
    "\n",
    "\n",
    "def get_angle_v2(p1, p2):\n",
    "    print(\">>정자세 검사하기<<\")\n",
    "    x = p2.x - p1.x\n",
    "    y = p2.y - p1.y\n",
    "    radian = math.atan2(y, x)\n",
    "    degree = radian * 180 / math.pi\n",
    "    if -180 < degree < -170 or 170 < degree < 180:\n",
    "        print(\"이사람 정면이다!!!!!!!!\")\n",
    "    else:\n",
    "        print(\"이사람 사이드다!!!!!!!!!!\")\n",
    "\n",
    "\n",
    "def is_sit(hip):\n",
    "    global timer_count\n",
    "    global status\n",
    "    global is_timer_running\n",
    "    print(\">>앉아있는지 검사하기<<\")\n",
    "\n",
    "    if hip > 1:\n",
    "        print(\"이사람 앉아있다!!!!\")\n",
    "        if is_timer_running == False:\n",
    "            if timer_count == 1:\n",
    "                status = 'q'\n",
    "                return -1\n",
    "            else:\n",
    "                print(\"시계 시작 =================================================================================\")\n",
    "                t = Timer(timesout, alert, args=())\n",
    "                t.start()\n",
    "                is_timer_running = True\n",
    "                timer_count += 1\n",
    "        else:\n",
    "            print(\"시간 가는중임 쩄든 가는중임\")\n",
    "    else:\n",
    "        print(\"이사람 서있다!!!!!!!!!!\")\n",
    "\n",
    "\n",
    "def alert():\n",
    "    global is_timer_running\n",
    "    is_timer_running = False\n",
    "    print(\"운동하라ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ\")\n",
    "\n",
    "\n",
    "def working():\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    # use webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        global is_running\n",
    "        global times\n",
    "\n",
    "        if is_running == False:\n",
    "            status = input(\"앉음 확인하기 1, 정자세 확인하기 2, 거북목 확인하기 3, 종료 q: \")\n",
    "            is_running = True\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if count % 10 == 0:\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"카메라가 인식되지않습니다.\")\n",
    "                continue\n",
    "            # 이미지를 좌우 반전을 시키고 BGR형태의 이미지를 RGB로 변환하여 활용합니다.\n",
    "            image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "            # 해당 영역에서 입력된 이미지를 분석하여 결과값을 도출해줍니다.\n",
    "            results = pose.process(image)\n",
    "            try:\n",
    "                for index in pose_list:\n",
    "                    if results.pose_landmarks.landmark[index].visibility < 0.0001:\n",
    "                        results.pose_landmarks.landmark[index].x = None\n",
    "                        results.pose_landmarks.landmark[index].y = None\n",
    "                        results.pose_landmarks.landmark[index].z = None\n",
    "\n",
    "                l_ear = results.pose_landmarks.landmark[7]\n",
    "                l_sh = results.pose_landmarks.landmark[11]\n",
    "                r_sh = results.pose_landmarks.landmark[12]\n",
    "                l_hip = results.pose_landmarks.landmark[23]\n",
    "\n",
    "                if status == '1':\n",
    "                    # ================앉아있는지?==================\n",
    "                    a = is_sit(l_hip.y)\n",
    "                    if a == -1:\n",
    "                        return -1\n",
    "\n",
    "                elif status == '2':\n",
    "                    # ================정자세인지?==================\n",
    "                    get_angle_v2(l_sh, r_sh)\n",
    "\n",
    "                elif status == '3':\n",
    "                    # ================거북목?======================\n",
    "                    # (시계 반대방향으로 도세요)\n",
    "                    is_turtleneck(l_ear.x, l_sh.x)\n",
    "\n",
    "                elif status == 'q':\n",
    "                    return -1\n",
    "                else:\n",
    "                    print(\"다른 값을 넣으세요.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                pass\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            # 이미지에 result에 저장된 좌표에 맞게 landmark를 표시합니다.\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            cv2.imshow('MediaPipe Pose', image)\n",
    "        # esc누르면 끝나요\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            is_running = False\n",
    "            break\n",
    "\n",
    "    pose.close()\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    working()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71be762759ae1b1747e1cfc60efa181cfc93ac416fe5084a790ec64e97c902b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
