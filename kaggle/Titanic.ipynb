{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "train1 = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "test1 = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "\n",
    "train = train1\n",
    "test = test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'Sex'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'Pclass'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'SibSp'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'Parch'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'Embarked'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDF = pd.DataFrame(train1)\n",
    "\n",
    "TDF1 = TDF.iloc[:,[0,1,2,4,5,6]]\n",
    "TDF1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDF2 = TDF1.pivot_table('Survived',index ='Sex',\n",
    "                        columns = 'Pclass', aggfunc='mean')\n",
    "TDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDF2.plot(kind='bar', stacked = True, title = 'Average Suvivors rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train1\n",
    "\n",
    "train_test_data = [train, test]\n",
    "\n",
    "for two_data in train_test_data:\n",
    "    two_data['Title'] = two_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train['Title'], train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(test['Title'], test['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Title').mean()['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'].fillna(train.groupby('Title')['Age'].transform('mean'), inplace = True)\n",
    "test['Age'].fillna(test.groupby('Title')['Age'].transform('mean'), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train,\n",
    "                     hue = 'Survived', aspect = 4)\n",
    "facet.map(sns.kdeplot, 'Age', shade = True)\n",
    "facet.set(xlim = (0, train['Age'].max()))\n",
    "\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for two_data in train_test_data:\n",
    "    two_data.loc[two_data['Age']<=18, 'Age'] =0\n",
    "    two_data.loc[(two_data['Age']>18) & (two_data['Age']<=35), 'Age'] = 1\n",
    "    two_data.loc[(two_data['Age']>35) & (two_data['Age']<=45), 'Age'] = 2\n",
    "    two_data.loc[(two_data['Age']>45) & (two_data['Age']<=60), 'Age'] = 3\n",
    "    two_data.loc[two_data['Age']>60, 'Age'] =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title_mapping ={'Mr':0, \"Rev\":0, 'Don':0, 'Capt':0, 'Jonkheer':0,\n",
    "               'Miss':1, 'Ms':1,\n",
    "               'Mrs':2, 'Lady':2, 'Dona':2, 'Mme':2, 'Countess':2,\n",
    "               'Master':3, 'Dr':3, 'Mlle':3,\n",
    "               'Col':4, 'Major':4, 'Sir':4}\n",
    "\n",
    "for two_data in train_test_data:\n",
    "    two_data['Title'] =two_data['Title'].map(Title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'Title'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = { 'male':0, 'female':1}\n",
    "\n",
    "for two_data in train_test_data:\n",
    "    two_data['Sex'] = two_data['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Name', axis =1, inplace = True)\n",
    "test.drop('Name', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected = 'Embarked'\n",
    "\n",
    "F_survived = train[train['Survived']==1][feature_selected].value_counts()\n",
    "F_dead = train[train['Survived']==0][feature_selected].value_counts()\n",
    "F_df = pd.DataFrame([F_survived,F_dead])\n",
    "F_df.index = ['Survived','Dead']\n",
    "F_df.plot(kind='bar',  stacked = 'True', figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\n",
    "\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class', '2nd class', '3rd class']\n",
    "df.plot(kind='bar', stacked=True, figsize = (10,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for two_data in train_test_data:\n",
    "    two_data['Embarked'] = two_data['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mapping ={'S':0, 'C':1, 'Q':2}\n",
    "\n",
    "for two_data in train_test_data:\n",
    "    two_data['Embarked'] = two_data['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(test.groupby('Pclass')['Fare'].transform('median'), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train,  #FacetGrid =  하나의 데이터를 여러 개의 plot으로 나눠서 보고자 할 때 사용\n",
    "                     hue = 'Survived', aspect = 4)\n",
    "#g = sns.FacetGrid(tips, col='time', row='smoker') #2x2 graph 그리기 \n",
    "#        g = g.map(plt.hist, 'total_bill') #각 분류별 total_bill의 histogram\n",
    "# tips 데이터를 column은 time을 기준으로 구분하고, row는 smoker를 기준으로 구분하여 plt.hist(histogram)으로 표현하라\n",
    "facet.map(sns.kdeplot, 'Fare', shade = True) # 부드러운 곡선\n",
    "facet.set(xlim = (0, train['Fare'].max()))\n",
    "\n",
    "facet.add_legend()\n",
    "\n",
    "plt.xlim(0,300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for two_data in train_test_data:\n",
    "    two_data.loc[two_data['Fare']<=5, 'Fare'] =0\n",
    "    two_data.loc[(two_data['Fare']>5) & (two_data['Fare']<=15), 'Fare'] = 1\n",
    "    two_data.loc[(two_data['Fare']>15) & (two_data['Fare']<=30), 'Fare'] = 2\n",
    "    two_data.loc[(two_data['Fare']>30) & (two_data['Fare']<=100), 'Fare'] = 3\n",
    "    two_data.loc[two_data['Fare']>100, 'Fare'] =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for two_data in train_test_data:\n",
    "    two_data['Cabin'] = two_data['Cabin'].str[:1]\n",
    "\n",
    "    \n",
    "train['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\n",
    "\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class', '2nd class', '3rd class']\n",
    "df.plot(kind='bar', stacked=True, figsize = (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].fillna(train.groupby('Pclass')['Cabin'].transform('median'), inplace =True)\n",
    "test['Cabin'].fillna(test.groupby('Pclass')['Cabin'].transform('median'), inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_mapping ={'A':2, 'B':2, 'C':2, 'T':2,\n",
    "               'D':1, 'G':1,\n",
    "               'E':0, 'F':0}\n",
    "\n",
    "for two_data in train_test_data:\n",
    "    two_data['Cabin']=two_data['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['familysize'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['familysize'] = test['SibSp'] + test['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train,\n",
    "                     hue = 'Survived', aspect = 4)\n",
    "facet.map(sns.kdeplot, 'familysize', shade = True)\n",
    "facet.set(xlim = (0, train['familysize'].max()))\n",
    "\n",
    "facet.add_legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for two_data in train_test_data:\n",
    "    two_data.loc[two_data['familysize']<=1, 'familysize'] =0\n",
    "    two_data.loc[(two_data['familysize']>1) & (two_data['familysize']<=2), 'familysize'] = 2\n",
    "    two_data.loc[(two_data['familysize']>2) & (two_data['familysize']<=5), 'familysize'] = 3\n",
    "    two_data.loc[two_data['familysize']>5, 'familysize'] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_drop =['Ticket', 'SibSp', 'Parch']\n",
    "train = train.drop(feature_drop, axis =1)\n",
    "train = train.drop('PassengerId', axis =1)\n",
    "\n",
    "test = test.drop(feature_drop, axis =1)\n",
    "\n",
    "train_x = train.drop('Survived', axis =1)\n",
    "train_y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits =10, shuffle = True, random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_clf = KNeighborsClassifier(n_neighbors =10)\n",
    "scoring1 = 'accuracy'\n",
    "\n",
    "score = cross_val_score(k_clf, train_x, train_y,\n",
    "                       cv=k_fold, scoring = scoring1)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clf = DecisionTreeClassifier()\n",
    "scoring1 = 'accuracy'\n",
    "\n",
    "score = cross_val_score(d_clf, train_x, train_y,\n",
    "                       cv=k_fold, scoring = scoring1)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clf = RandomForestClassifier(n_estimators =15)\n",
    "scoring1 = 'accuracy'\n",
    "\n",
    "score = cross_val_score(r_clf, train_x, train_y,\n",
    "                       cv=k_fold, scoring = scoring1)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clf = RandomForestClassifier(n_estimators =15)\n",
    "scoring1 = 'accuracy'\n",
    "\n",
    "score = cross_val_score(r_clf, train_x, train_y,\n",
    "                       cv=k_fold, scoring = scoring1)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_clf = SVC()\n",
    "scoring1 = 'accuracy'\n",
    "\n",
    "score = cross_val_score(s_clf, train_x, train_y,\n",
    "                       cv=k_fold, scoring = scoring1)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_clf = SVC()\n",
    "scoring1 = 'accuracy'\n",
    "\n",
    "score = cross_val_score(s_clf, train_x, train_y,\n",
    "                       cv=k_fold, scoring = scoring1)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Load the training data\n",
    "# train_x, train_y = load_data()\n",
    "\n",
    "# Create the model\n",
    "model = SVC()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'C': [0.1, 1, 4, 7,10],\n",
    "              'kernel': ['linear', 'rbf'], # The RBF kernel is a popular choice for non-linear classification and regression problems \n",
    "                                           # The RBF kernel is defined as the exponential of the negative Euclidean distance between two points, \n",
    "                                           # scaled by a gamma parameter\n",
    "              'degree':[1,2,3,4,5,6,7],\n",
    "              'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Define the scoring metric\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=accuracy_scorer)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Load the training data\n",
    "# X_train, y_train = load_data()\n",
    "\n",
    "# Create the model\n",
    "modelx = XGBClassifier()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'max_depth': [3, 5, 7],\n",
    "              'learning_rate': [0.1, 0.2, 0.3],\n",
    "              'n_estimators': [50, 100, 200],\n",
    "              'subsample': [0.5, 0.8, 1],\n",
    "              'colsample_bytree': [0.5, 0.8, 1],\n",
    "              'reg_alpha': [0, 0.1, 0.2],\n",
    "              'reg_lambda': [0, 0.1, 0.2]}\n",
    "\n",
    "# Define the scoring metric\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=modelx, param_grid=param_grid, scoring=accuracy_scorer)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "x_model =XGBClassifier(max_depth= 7,\n",
    "                       learning_rate = 0.1,\n",
    "                       n_estimators =50,\n",
    "                       subsample = 0.8,\n",
    "                       colsample_bytree= 0.5,\n",
    "                       reg_alpha = 0.1,\n",
    "                       reg_lambda = 0,\n",
    "                       random_state =123)\n",
    "\n",
    "x_model.fit(train_x, train_y)\n",
    "\n",
    "pred = x_model.predict_proba(test_x)[:,1]\n",
    "\n",
    "pred_label = np.where(pred>0.5,1 , 0)\n",
    "\n",
    "submission =pd.DataFrame({'PassengerId':test['PassengerId'], 'Survived': pred_label})\n",
    "submission.to_csv('submission0112_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80cc27e9a0e8aa59b18a6f502b8a24c9fe77be3bcd87d0900d8763aa62f81a4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
